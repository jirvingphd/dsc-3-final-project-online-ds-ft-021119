{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: \n",
    "* Student pace: self paced / part time / full time\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: \n",
    "* Blog post URL:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **OBTAIN:**\n",
    "    - **Import data, inspect, check for datatypes to convert and null values**<br>\n",
    "        - Display header and info\n",
    "        - Drop any unneeded columns (df.drop(['col1','col2'],axis=1)\n",
    "\n",
    "2. **SCRUB: cast data types, identify outliers, check for multicollinearity, normalize data**<br>\n",
    "    - Check and cast data types\n",
    "        - [ ] Check for #'s that are store as objects (df.info())\n",
    "            - when converting to #'s, look for odd values (like many 0's), or strings that can't be converted\n",
    "            - Decide how to deal weird/null values (df.unique(), df.isna().sum(), df.describe()-min/max, etc\n",
    "        - [ ]  Check for categorical variables stored as integers\n",
    "    - [ ] Check for missing values  (df.isna().sum())\n",
    "        - Can drop rows or colums\n",
    "        - For missing numeric data with median or bin/convert to categorical\n",
    "        - For missing categorical data: make NaN own category OR replace with most common category\n",
    "    - [ ] Check for multicollinearity\n",
    "         - use seaborn to make correlation matrix plot [Evernote Link](https://www.evernote.com/l/AArNyaEwjA5JUL6I9PazHs_ts_hU-m7ja1I/) \n",
    "        - Good rule of thumb is anything over 0.75 corr is high, remove the variable that has the most correl with the largest # of variables\n",
    "    - [ ] Normalize data (may want to do after some exploring)\n",
    "        - Most popular is Z-scoring (but won't fix skew) \n",
    "        - Can log-transform to fix skewed data\n",
    "    \n",
    "            \n",
    "3. **EXPLORE:Check distributions, outliers, etc**\n",
    "    - [ ] Check scales, ranges (df.describe())\n",
    "    - [ ] Check histograms to get an idea of distributions (df.hist()) and dat transformations to perform\n",
    "        - Can also do kernel density estimates\n",
    "    - [ ] Use scatterplots to check for linearity and possible categorical variables (df.plot(kind-'scatter')\n",
    "        - categoricals will look like vertical lines\n",
    "    - [ ] Use pd.plotting.scatter_matrix to visualize possible relationships\n",
    "    - [ ] Check for linearity\n",
    "\n",
    "   \n",
    "4. **FIT AN INITIAL MODEL:** \n",
    "    - Various forms, detail later...\n",
    "    - **Assessing the model:**\n",
    "        - Assess parameters (slope,intercept)\n",
    "        - Check if the model explains the variation in the data (RMSE, F, R_square)\n",
    "        - *Are the coeffs, slopes, intercepts in appropriate units?*\n",
    "        - *Whats the impact of collinearity? Can we ignore?*\n",
    "5. **Revise the fitted model**\n",
    "    - Multicollinearity is big issue for lin regression and cannot fully remove it\n",
    "    - Use the predictive ability of model to test it (like R2 and RMSE)\n",
    "    - Check for missed non-linearity\n",
    "6. **Holdout validation / Train/test split**\n",
    "    - use sklearn train_test_split \n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View our documentation at https://bs-ds.readthedocs.io/en/latest/bs_ds.html\n",
      "Recommended import method:\n",
      ">> from bs_ds import *\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs_ds import *\n",
    "# import bs_ds as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_pandas()\n",
    "ignore_warnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chosen Dataset\n",
    "\n",
    "- https://www.kaggle.com/slonnadube/recidivism-for-offenders-released-from-prison\n",
    "- Statistics about recidivism in prisoners from a 3 year prisoner\n",
    "- Features:\n",
    "    - Fiscal Year Released\n",
    "    - Recidivism Reporting Year\n",
    "    - Race - Ethnicity\n",
    "    - Age At Release\n",
    "    - Convicting Offense Classification\n",
    "    - Convicting Offense Type\n",
    "    - Convicting Offense Subtype\n",
    "    - Main Supervising District\n",
    "    - Release Type\n",
    "    - Release type: Paroled to Detainder united\n",
    "    - Part of Target Population\n",
    "    - Recidivism - Return to Prison numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Kaggle Listing:\n",
    ">For recidivism prediction the full dataset containing 26021 records was used. The name of the data set is: \"3-Year_Recidivism_for_Offenders_Released_from_Prison_in_Iowa_elaborated\". All the variables related to recidivism were excluded from the dataset, except the response variable: 'Recidivism - return to prison'. The response variable was turned into a numeric vector of (0,1), where 1 means 'yes recidivism' and 0 means 'no recidivism'. \n",
    "Other variables related to recidivism were of course not used in the predictive analysis. There are 26021 records in this dataset.\n",
    "\n",
    "> Another dataset was constructed using the initial one. This dataset is called 'prison_recidivists_with_recidivism_type_only'. It contains the records of those recidivists from the initial file for whom the type of recidivism has been recorded and documented.\n",
    "\n",
    "> This one done in order to enable the comparison between the seriousness of the initial offense and the type of recidivism. Therefore, only the records containing both types were left in this dataset, and the rest were filtered out. The second dataset containing data recidivists only is comprised of 6718 records.\n",
    "\n",
    "The variables in the data set\n",
    "\n",
    "- Fiscal Year Released Fiscal year (year ending June 30) for which the offender was released from prison.\n",
    "\n",
    "- Recidivism Reporting Year \n",
    "    - Fiscal year (year ending June 30) that marks the end of the 3-year tracking period. For example, offenders exited prison in FY 2012 are found in recidivism reporting year FY 2015.\n",
    "\n",
    "- Race - Ethnicity \n",
    "    - Offender's Race and Ethnicity\n",
    "\n",
    "- Convicting Offense Classification \n",
    "    - Maximum penalties: A Felony = Life; B Felony = 25 or 50 years; C Felony = 10 years; D Felony = 5 years; Aggravated Misdemeanor = 2 years; Serious Misdemeanor = 1 year; Simple Misdemeanor = 30 days\n",
    "\n",
    "- Convicting Offense Type General category for the most serious offense for which the offender was placed in prison.\n",
    "\n",
    "- Convicting Offense Subtype \n",
    "    - Further classification of the most serious offense for which the offender was placed in prison.\n",
    "\n",
    "- Release Type \n",
    "    - Reasoning for Offender's release from prison.\n",
    "\n",
    "- Main Supervising District \n",
    "    - The Judicial District supervising the offender for the longest time during the tracking period.\n",
    "\n",
    "- Recidivism - Return to Prison \n",
    "    - No = No Recidivism; Yes = Prison admission for any reason within the 3-year tracking period\n",
    "\n",
    "- Days to Recidivism \n",
    "    - Number of days it took before the offender returned to prison.\n",
    "\n",
    "- New Conviction Offense Classification The same as the initial offense classification.\n",
    "\n",
    "- New Conviction Offense Type The same as the initial offense type.\n",
    "\n",
    "- New Conviction Offense Sub Type The same as the initial offense subtype.\n",
    "\n",
    "- Part of Target Population \n",
    "    - The Department of Corrections has undertaken specific strategies to reduce recidivism rates for prisoners who are on parole and are part of the target population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env-ext",
   "language": "python",
   "name": "learn-env-ext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 534.8,
   "position": {
    "height": "556.4px",
    "left": "-7.40002px",
    "right": "20px",
    "top": "105px",
    "width": "427.4px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
